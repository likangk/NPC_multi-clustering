## Three groups of Multi-view learning
- Multiple kernel learning:   
  Exploit kernels that naturally correspond to different views and combine kernels either linearly or ono-linearly to improve learning performance.
- Subspace learning:  
  Aim to obtain a latent subspace shared by multiple views by assuming that the input views are penerated from this latent subspace.
- Co-training:  
  Alternately to maximize the mutual agreement on two distinct views of the data.  
 
Conclusion:  **consensus** or **complementary**
